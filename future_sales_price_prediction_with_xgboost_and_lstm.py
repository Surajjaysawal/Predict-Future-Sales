# -*- coding: utf-8 -*-
"""Future Sales Price Prediction With XGBoost and LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cBZMlxkTdvkHA0dIuQ0yFASljKR2FePC
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

import warnings
warnings.filterwarnings('ignore')

from lightgbm import LGBMRegressor
from xgboost import XGBRegressor

import tensorflow as tf
from tensorflow.keras.layers.experimental import preprocessing

from pandas_profiling import ProfileReport

sns.set(style='whitegrid', font_scale=1.5)


RANDOM_STATE=42

sales_data = pd.read_csv('sales_train.csv')
test_data = pd.read_csv('test.csv')
item_categories = pd.read_csv('item_categories.csv')
items = pd.read_csv('items.csv')
shops = pd.read_csv('shops.csv')

print(sales_data.head())
print(sales_data.info())

sales_data['date'] = pd.to_datetime(sales_data['date'], format= '%d.%m.%Y')
sales_data.info()

print(test_data.head())
print(test_data.info())

print(item_categories.head())
print(item_categories.info())

print(items.head())
print(items.info())

print(shops.head())
print(shops.info())

SalesData = sales_data.copy()
SalesData = SalesData.pivot_table(
    index=['shop_id', 'item_id'],
    values=['item_cnt_day'],
    columns=['date_block_num'],
    fill_value=0,
    aggfunc='sum'
).reset_index()

SalesData

Final_Dataset = pd.merge(test_data,SalesData,on =['item_id','shop_id'],how = 'left')

Final_Dataset.head()

Final_Dataset.isnull().sum()

Final_Dataset.fillna(0,inplace=True)
Final_Dataset.isnull().sum()

Final_Dataset.drop(['ID','shop_id','item_id'], axis=1,inplace=True)
Final_Dataset.head()

Final_Dataset.shape

X_train, y_train = Final_Dataset.values[:,:-2], Final_Dataset.values[:, -2:-1].ravel()
X_valid, y_valid = Final_Dataset.values[:,1:-1], Final_Dataset.values[:, -1:].ravel()
X_test = Final_Dataset.values[:, 2:]

X_train

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# xgb_model = XGBRegressor(
#     max_depth=16,
#     n_estimators=200,
#     seed=RANDOM_STATE,
# )
# 
# xgb_model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric="rmse",
#               eval_set=[(X_train, y_train), (X_valid, y_valid)], verbose=10)

y_pred = xgb_model.predict(X_valid)
print('XGBoost RMSE =', mean_squared_error(y_valid, y_pred, squared=False))





tf.keras.backend.clear_session()

lstm_model = tf.keras.Sequential([
    tf.keras.layers.Reshape(input_shape=(32,), target_shape=(32, 1,)),
    tf.keras.layers.LSTM(units=32, input_shape=(32, 1)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(1)
])

lstm_model.compile(
    loss='mse',
    optimizer=tf.keras.optimizers.Adam(0.1),
    metrics=['mse']
)

lstm_model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=10)
# 
# lstm_model.fit(X_train, y_train, batch_size=4096, epochs=30,
#           validation_data=(X_valid, y_valid),
#           callbacks=[early_stop])

y_pred = lstm_model.predict(X_valid)
print('LSTM RMSE =', mean_squared_error(y_valid, y_pred, squared=False))





Submission = pd.read_csv('sample_submission.csv')



result_df = Submission.copy()
result_df['XGB'] = xgb_model.predict(X_test)
result_df['LSTM'] = lstm_model.predict(X_test)
result_df

TARGET = 'item_cnt_month'

result_df[TARGET] = 0.05 * result_df['XGB'] + 0.9 * result_df['LSTM']

Submission = result_df[['ID', TARGET]]
Submission.to_csv(f'output.csv', index=False)
Submission





